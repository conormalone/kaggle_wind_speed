{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conny\\AppData\\Local\\Temp\\ipykernel_3148\\1690104781.py:1: DtypeWarning: Columns (0,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('train.csv', header=[0, 1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Wind speed (m/s)</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Wind speed, Standard deviation (m/s)</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Generator RPM (RPM)</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Blade angle (pitch position) A (°)</th>\n",
       "      <th>training</th>\n",
       "      <th>target_feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Turbine</th>\n",
       "      <th>Unnamed: 1_level_1</th>\n",
       "      <th>Kelmarsh 2</th>\n",
       "      <th>Kelmarsh 3</th>\n",
       "      <th>Kelmarsh 4</th>\n",
       "      <th>Kelmarsh 5</th>\n",
       "      <th>Kelmarsh 6</th>\n",
       "      <th>Kelmarsh 2</th>\n",
       "      <th>Kelmarsh 3</th>\n",
       "      <th>Kelmarsh 4</th>\n",
       "      <th>...</th>\n",
       "      <th>Kelmarsh 4</th>\n",
       "      <th>Kelmarsh 5</th>\n",
       "      <th>Kelmarsh 6</th>\n",
       "      <th>Kelmarsh 2</th>\n",
       "      <th>Kelmarsh 3</th>\n",
       "      <th>Kelmarsh 4</th>\n",
       "      <th>Kelmarsh 5</th>\n",
       "      <th>Kelmarsh 6</th>\n",
       "      <th>Unnamed: 52_level_1</th>\n",
       "      <th>Unnamed: 53_level_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-01 00:00:00</td>\n",
       "      <td>9.112875</td>\n",
       "      <td>9.197829</td>\n",
       "      <td>8.795919</td>\n",
       "      <td>8.749384</td>\n",
       "      <td>7.684954</td>\n",
       "      <td>1.104222</td>\n",
       "      <td>1.096619</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>...</td>\n",
       "      <td>1768.215088</td>\n",
       "      <td>1733.296875</td>\n",
       "      <td>1603.749390</td>\n",
       "      <td>0.183487</td>\n",
       "      <td>0.135490</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>8.602844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-01 00:10:00</td>\n",
       "      <td>8.319863</td>\n",
       "      <td>9.350296</td>\n",
       "      <td>8.762059</td>\n",
       "      <td>8.652318</td>\n",
       "      <td>7.421576</td>\n",
       "      <td>1.207655</td>\n",
       "      <td>0.916610</td>\n",
       "      <td>0.956899</td>\n",
       "      <td>...</td>\n",
       "      <td>1770.806885</td>\n",
       "      <td>1737.218262</td>\n",
       "      <td>1572.769409</td>\n",
       "      <td>0.051998</td>\n",
       "      <td>0.086999</td>\n",
       "      <td>0.095998</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>8.125226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-01 00:20:00</td>\n",
       "      <td>8.799176</td>\n",
       "      <td>8.510402</td>\n",
       "      <td>9.533566</td>\n",
       "      <td>8.166586</td>\n",
       "      <td>7.797040</td>\n",
       "      <td>1.124029</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>1.343180</td>\n",
       "      <td>...</td>\n",
       "      <td>1766.002319</td>\n",
       "      <td>1698.699219</td>\n",
       "      <td>1655.049316</td>\n",
       "      <td>0.168988</td>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.087998</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.016</td>\n",
       "      <td>True</td>\n",
       "      <td>7.551986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-01 00:30:00</td>\n",
       "      <td>8.392921</td>\n",
       "      <td>8.825861</td>\n",
       "      <td>8.990985</td>\n",
       "      <td>7.877046</td>\n",
       "      <td>7.750090</td>\n",
       "      <td>1.219647</td>\n",
       "      <td>1.218454</td>\n",
       "      <td>0.970566</td>\n",
       "      <td>...</td>\n",
       "      <td>1783.569824</td>\n",
       "      <td>1661.264526</td>\n",
       "      <td>1678.571777</td>\n",
       "      <td>0.084492</td>\n",
       "      <td>0.133995</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.912114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0_level_0            Timestamp Wind speed (m/s)             \\\n",
       "             Turbine   Unnamed: 1_level_1       Kelmarsh 2 Kelmarsh 3   \n",
       "0                 id                  NaN              NaN        NaN   \n",
       "1                  0  2017-10-01 00:00:00         9.112875   9.197829   \n",
       "2                  1  2017-10-01 00:10:00         8.319863   9.350296   \n",
       "3                  2  2017-10-01 00:20:00         8.799176   8.510402   \n",
       "4                  3  2017-10-01 00:30:00         8.392921   8.825861   \n",
       "\n",
       "                                   Wind speed, Standard deviation (m/s)  \\\n",
       "  Kelmarsh 4 Kelmarsh 5 Kelmarsh 6                           Kelmarsh 2   \n",
       "0        NaN        NaN        NaN                                  NaN   \n",
       "1   8.795919   8.749384   7.684954                             1.104222   \n",
       "2   8.762059   8.652318   7.421576                             1.207655   \n",
       "3   9.533566   8.166586   7.797040                             1.124029   \n",
       "4   8.990985   7.877046   7.750090                             1.219647   \n",
       "\n",
       "                         ... Generator RPM (RPM)                            \\\n",
       "  Kelmarsh 3 Kelmarsh 4  ...          Kelmarsh 4   Kelmarsh 5   Kelmarsh 6   \n",
       "0        NaN        NaN  ...                 NaN          NaN          NaN   \n",
       "1   1.096619   0.999588  ...         1768.215088  1733.296875  1603.749390   \n",
       "2   0.916610   0.956899  ...         1770.806885  1737.218262  1572.769409   \n",
       "3   0.992841   1.343180  ...         1766.002319  1698.699219  1655.049316   \n",
       "4   1.218454   0.970566  ...         1783.569824  1661.264526  1678.571777   \n",
       "\n",
       "  Blade angle (pitch position) A (°)                                   \\\n",
       "                          Kelmarsh 2 Kelmarsh 3 Kelmarsh 4 Kelmarsh 5   \n",
       "0                                NaN        NaN        NaN        NaN   \n",
       "1                           0.183487   0.135490   0.001053     0.0000   \n",
       "2                           0.051998   0.086999   0.095998     0.0605   \n",
       "3                           0.168988   0.056997   0.087998     0.0090   \n",
       "4                           0.084492   0.133995   0.017500     0.0000   \n",
       "\n",
       "                        training      target_feature  \n",
       "  Kelmarsh 6 Unnamed: 52_level_1 Unnamed: 53_level_1  \n",
       "0        NaN                 NaN                 NaN  \n",
       "1      0.000                True            8.602844  \n",
       "2      0.000                True            8.125226  \n",
       "3      0.016                True            7.551986  \n",
       "4      0.000                True            7.912114  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('train.csv', header=[0, 1])\n",
    "meta_df = pd.read_csv(\"metaData.csv\")\n",
    "#get target feature out of df\n",
    "target = df[['Timestamp',\"target_feature\"]].rename(columns={\"Unnamed: 1_level_1\":\"\",\"Unnamed: 53_level_1\":\"\"})\n",
    "target.columns = [''.join(col).strip() for col in target.columns] \n",
    "target.drop(target.iloc[0].name, inplace=True)\n",
    "target[\"Timestamp\"] = pd.to_datetime(target[\"Timestamp\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['_'.join(col).strip() for col in df.columns]  # Flatten multi-index\n",
    "df.rename(columns={\"Timestamp_Unnamed: 1_level_1\": \"Timestamp\"}, inplace=True)  # Rename timestamp\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Value</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Turbine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130609</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wind speed (m/s)</td>\n",
       "      <td>Kelmarsh 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130610</th>\n",
       "      <td>2017-10-01 00:00:00</td>\n",
       "      <td>9.112875</td>\n",
       "      <td>Wind speed (m/s)</td>\n",
       "      <td>Kelmarsh 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130611</th>\n",
       "      <td>2017-10-01 00:10:00</td>\n",
       "      <td>8.319863</td>\n",
       "      <td>Wind speed (m/s)</td>\n",
       "      <td>Kelmarsh 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130612</th>\n",
       "      <td>2017-10-01 00:20:00</td>\n",
       "      <td>8.799176</td>\n",
       "      <td>Wind speed (m/s)</td>\n",
       "      <td>Kelmarsh 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130613</th>\n",
       "      <td>2017-10-01 00:30:00</td>\n",
       "      <td>8.392921</td>\n",
       "      <td>Wind speed (m/s)</td>\n",
       "      <td>Kelmarsh 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp     Value          Variable     Turbine\n",
       "130609                 NaT       NaN  Wind speed (m/s)  Kelmarsh 2\n",
       "130610 2017-10-01 00:00:00  9.112875  Wind speed (m/s)  Kelmarsh 2\n",
       "130611 2017-10-01 00:10:00  8.319863  Wind speed (m/s)  Kelmarsh 2\n",
       "130612 2017-10-01 00:20:00  8.799176  Wind speed (m/s)  Kelmarsh 2\n",
       "130613 2017-10-01 00:30:00  8.392921  Wind speed (m/s)  Kelmarsh 2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = df.melt(id_vars=[\"Timestamp\"], \n",
    "                  var_name=\"Variable_Turbine\", \n",
    "                  value_name=\"Value\")\n",
    "\n",
    "# Split 'Variable_Turbine' into 'Variable' and 'Turbine'\n",
    "df_long[[\"Variable\", \"Turbine\"]] = df_long[\"Variable_Turbine\"].str.rsplit(\"_\", n=1, expand=True)\n",
    "df_long.drop(columns=[\"Variable_Turbine\"], inplace=True)\n",
    "df_long=df_long[df_long[\"Turbine\"].str.contains(\"Kelmarsh\")]\n",
    "df_long.head()  # View the reshaped dataframedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df_long.pivot(index=['Timestamp', 'Turbine'], columns='Variable', values='Value').reset_index()\n",
    "df_wide = df_wide[df_wide[\"Timestamp\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[\"total_hub_height\"] = meta_df[\"Hub Height (m)\"]  + meta_df[\"Elevation (m)\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_meta = df_wide.merge(meta_df, left_on=\"Turbine\",right_on=\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_wide_meta.merge(target, on=\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = meta_df[['Latitude', 'Longitude', 'total_hub_height']].values  # take location vars from meta_data\n",
    "\n",
    "# Compute pairwise distances\n",
    "distances = distance_matrix(coords, coords)  # Shape: (num_turbines, num_turbines)\n",
    "\n",
    "# Define edges: Connect turbines within a threshold distance\n",
    "threshold = 5000  # Example: 5000 meters\n",
    "edges = np.argwhere(distances < threshold)\n",
    "\n",
    "# Remove self-loops\n",
    "edges = edges[edges[:, 0] != edges[:, 1]]\n",
    "\n",
    "# Convert to PyG format\n",
    "edge_index = torch.tensor(edges.T, dtype=torch.long)  # Shape: (2, num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "class WindTurbineGraphDataset(Dataset):\n",
    "    def __init__(self, df, edge_threshold=0.5, transform=None):\n",
    "        super().__init__(transform)\n",
    "        self.df = df\n",
    "        self.scaler = StandardScaler()\n",
    "        self.edge_threshold = edge_threshold  # Define how nodes connect\n",
    "\n",
    "        # Extract unique timestamps\n",
    "        self.timestamps = df[\"Timestamp\"].unique()\n",
    "        \n",
    "        # Standardize features\n",
    "        feature_cols = df.columns.difference([\"Timestamp\", \"Turbine\", \"target_feature\"])\n",
    "        self.df[feature_cols] = self.scaler.fit_transform(self.df[feature_cols])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.timestamps)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"Convert a single timestamp into a graph\"\"\"\n",
    "        timestamp = self.timestamps[idx]\n",
    "        df_t = self.df[self.df[\"Timestamp\"] == timestamp]\n",
    "\n",
    "        # Extract node features\n",
    "        x = torch.tensor(df_t.drop(columns=[\"Timestamp\", \"Turbine\", \"target_feature\"]).values, dtype=torch.float)\n",
    "\n",
    "        # Create edges (fully connected or distance-based)\n",
    "        num_nodes = len(df_t)\n",
    "        edge_index = torch.tensor(list(combinations(range(num_nodes), 2)), dtype=torch.long).T  # Fully connected\n",
    "\n",
    "        # Extract target (graph-level label)\n",
    "        y = torch.tensor([df_t[\"target_feature\"].mean()], dtype=torch.float)  # Example: mean wind speed\n",
    "\n",
    "        return Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class WindGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Pool over the graph\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_3148\\3575466047.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m torch_geometric.loader \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m torch.optim \u001b[38;5;28;01mas\u001b[39;00m optim\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Prepare dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m dataset = WindTurbineGraphDataset(df)\n\u001b[32m      6\u001b[39m train_loader = DataLoader(dataset, batch_size=\u001b[32m16\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Initialize model\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_3148\\2137676564.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, df, edge_threshold, transform)\u001b[39m\n\u001b[32m     16\u001b[39m         self.timestamps = df[\u001b[33m\"Timestamp\"\u001b[39m].unique()\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# Standardize features\u001b[39;00m\n\u001b[32m     19\u001b[39m         feature_cols = df.columns.difference([\u001b[33m\"Timestamp\"\u001b[39m, \u001b[33m\"Turbine\"\u001b[39m, \u001b[33m\"target_feature\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         self.df[feature_cols] = self.scaler.fit_transform(self.df[feature_cols])\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m     @wraps(f)\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    321\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m             return_tuple = (\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    914\u001b[39m                 )\n\u001b[32m    915\u001b[39m \n\u001b[32m    916\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    890\u001b[39m             Fitted scaler.\n\u001b[32m    891\u001b[39m         \"\"\"\n\u001b[32m    892\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    926\u001b[39m         self : object\n\u001b[32m    927\u001b[39m             Fitted scaler.\n\u001b[32m    928\u001b[39m         \"\"\"\n\u001b[32m    929\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         X = validate_data(\n\u001b[32m    931\u001b[39m             self,\n\u001b[32m    932\u001b[39m             X,\n\u001b[32m    933\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2940\u001b[39m             out = y\n\u001b[32m   2941\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2942\u001b[39m             out = X, y\n\u001b[32m   2943\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2945\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2947\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) from complex_warning\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'id'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Prepare dataset\n",
    "dataset = WindTurbineGraphDataset(df)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WindGNN(in_channels=dataset[0].x.shape[1], hidden_channels=64, out_channels=1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.mse_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        print(predictions)  # Graph-level predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
